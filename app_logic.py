# Este arquivo conter√° a l√≥gica de neg√≥cios principal do aplicativo,
# separada da interface do usu√°rio (GUI).
# O objetivo √© tornar o c√≥digo mais modular e reutiliz√°vel,
# facilitando a adapta√ß√£o para outras plataformas, como o Android.

import requests
import pandas as pd
import time
import logging
import copy
from datetime import datetime, timedelta
import robust_services
import os
from indicators import calculate_rsi, calculate_bollinger_bands, calculate_macd, calculate_emas, calculate_hilo_signals
from notification_service import send_telegram_alert
from pycoingecko import CoinGeckoAPI
from app_state import load_coin_mapping_cache, save_coin_mapping_cache, get_last_fetch_timestamp, update_last_fetch_timestamp
from utils import get_application_path
import json
import sys

class AppLogic:
    def __init__(self, update_interval_hours=24):
        self.config = self.load_config()
        self.alert_history = self.load_alert_history()
        self.coin_list_path = os.path.join(get_application_path(), "all_coins.json")
        self.update_interval = timedelta(hours=update_interval_hours)
        self.cg = CoinGeckoAPI()
        self.all_coins = self._load_or_fetch_coins()

    def _fetch_coins_from_api(self):
        """Fetches the complete list of coins from the CoinGecko API."""
        logging.info("Fetching coin list from CoinGecko API...")
        try:
            coins = self.cg.get_coins_list()
            with open(self.coin_list_path, 'w', encoding='utf-8') as f:
                json.dump(coins, f, indent=2)
            logging.info(f"Successfully fetched and saved {len(coins)} coins.")
            return coins
        except Exception as e:
            logging.error(f"Failed to fetch coin list from CoinGecko: {e}")
            return None

    def _load_or_fetch_coins(self):
        """Loads the coin list from the local cache or fetches it if outdated or non-existent."""
        if os.path.exists(self.coin_list_path):
            file_mod_time = datetime.fromtimestamp(os.path.getmtime(self.coin_list_path))
            if datetime.now() - file_mod_time < self.update_interval:
                logging.info("Loading coin list from local cache.")
                with open(self.coin_list_path, 'r', encoding='utf-8') as f:
                    return json.load(f)

        return self._fetch_coins_from_api()

    def get_all_coins(self):
        """Returns the list of all coins."""
        return self.all_coins

    def get_coin_display_list(self):
        """Returns a list of formatted strings for display (e.g., 'Bitcoin (BTC)')."""
        if not self.all_coins:
            return []

        # Sort by name for user-friendly display
        sorted_coins = sorted(self.all_coins, key=lambda x: x['name'])

        return [f"{coin['name']} ({coin['symbol'].upper()})" for coin in sorted_coins]

    def get_symbol_from_display_name(self, display_name):
        """Extracts the symbol from the display name format."""
        try:
            return display_name.split('(')[-1].replace(')', '').strip()
        except:
            return None

    def load_alert_history(self):
        """Carrega o hist√≥rico de alertas do arquivo alert_history.json."""
        history_path = os.path.join(get_application_path(), "alert_history.json")
        try:
            with open(history_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except (FileNotFoundError, json.JSONDecodeError):
            return []

    def save_alert_history(self):
        """Salva o hist√≥rico de alertas atual no arquivo alert_history.json."""
        history_path = os.path.join(get_application_path(), "alert_history.json")
        try:
            with open(history_path, 'w', encoding='utf-8') as f:
                json.dump(self.alert_history, f, indent=2)
            logging.info("Hist√≥rico de alertas salvo com sucesso.")
        except Exception as e:
            logging.error(f"N√£o foi poss√≠vel salvar o hist√≥rico de alertas: {e}")

    def log_and_save_alert(self, symbol, trigger, data):
        """Adiciona uma nova entrada de alerta ao hist√≥rico."""
        alert_entry = {'timestamp': datetime.now().isoformat(), 'symbol': symbol, 'trigger': trigger, 'data': data}
        self.alert_history.insert(0, alert_entry)
        if len(self.alert_history) > 200:
            self.alert_history = self.alert_history[:200]

    def load_config(self):
        """Carrega a configura√ß√£o do aplicativo a partir do arquivo config.json."""
        config_path = os.path.join(get_application_path(), "config.json")
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except (FileNotFoundError, json.JSONDecodeError):
            return {"cryptos_to_monitor": [], "telegram_bot_token": "", "telegram_chat_id": "", "check_interval_seconds": 300}

    def save_config(self):
        """Salva a configura√ß√£o atual no arquivo config.json."""
        config_path = os.path.join(get_application_path(), "config.json")
        try:
            with open(config_path, 'w', encoding='utf-8') as f:
                json.dump(self.config, f, indent=2)
            logging.info("Configura√ß√µes salvas com sucesso.")
        except Exception as e:
            logging.error(f"Erro ao salvar configura√ß√µes: {e}")

cg_client = CoinGeckoAPI()

ALERT_SUMMARIES = {
    # RSI
    'RSI_SOBRECOMPRA': "RSI > 70: Ativo pode estar supervalorizado, risco de corre√ß√£o.",
    'RSI_SOBREVENDA': "RSI < 30: Ativo pode estar desvalorizado, potencial de alta.",
    # Bandas de Bollinger
    'PRECO_ACIMA_BANDA_SUPERIOR': "Pre√ßo acima da Banda de Bollinger Superior: Alta volatilidade, poss√≠vel sobrecompra.",
    'PRECO_ABAIXO_BANDA_INFERIOR': "Pre√ßo abaixo da Banda de Bollinger Inferior: Alta volatilidade, poss√≠vel sobrevenda.",
    # MACD
    'CRUZAMENTO_MACD_ALTA': "MACD cruzou para cima da linha de sinal: Sinal de momentum de alta.",
    'CRUZAMENTO_MACD_BAIXA': "MACD cruzou para baixo da linha de sinal: Sinal de momentum de baixa.",
    # M√©dias M√≥veis
    'CRUZ_DOURADA': "MME 50 cruzou acima da MME 200: Forte sinal de tend√™ncia de alta.",
    'CRUZ_DA_MORTE': "MME 50 cruzou abaixo da MME 200: Forte sinal de tend√™ncia de baixa.",
    # Padr√£o de Volume
    'VOLUME_ANORMAL': "Volume de negocia√ß√£o significativamente acima da m√©dia. Indica forte interesse ou evento.",
    # Padr√£o de Velas (Exemplo)
    'MARTELO_ALTA': "Padr√£o de vela 'Martelo': Pode indicar uma revers√£o de baixa para alta.",
    'ESTRELA_CADENTE_BAIXA': "Padr√£o de vela 'Estrela Cadente': Pode indicar uma revers√£o de alta para baixa."
}

def get_klines_data(symbol, interval='1h', limit=300):
    """Busca dados de k-lines da Binance com cache, rate limiting e valida√ß√£o."""
    if not robust_services.DataValidator.validate_symbol(symbol):
        logging.warning(f"Tentativa de busca por s√≠mbolo inv√°lido: {symbol}")
        return None
    
    cache_args = {'func': 'get_klines_data', 'symbol': symbol, 'interval': interval, 'limit': limit}
    cached_df = robust_services.data_cache.get(cache_args, ttl=180)
    if cached_df is not None:
        return cached_df
    
    robust_services.rate_limiter.wait_if_needed()
    url = "https://api.binance.com/api/v3/klines"
    params = {'symbol': symbol, 'interval': interval, 'limit': limit}
    
    try:
        response = requests.get(url, params=params, timeout=10)
        response.raise_for_status()
        df = pd.DataFrame(response.json(), columns=['open_time', 'open', 'high', 'low', 'close', 'volume', 'close_time', 'quote_asset_volume', 'number_of_trades', 'taker_buy_base_asset_volume', 'taker_buy_quote_asset_volume', 'ignore'])
        df['close'] = df['close'].apply(robust_services.DataValidator.safe_price)
        df['high'] = df['high'].apply(robust_services.DataValidator.safe_price)
        df['low'] = df['low'].apply(robust_services.DataValidator.safe_price)
        robust_services.data_cache.set(cache_args, df)
        return df
    except requests.exceptions.RequestException as e:
        logging.error(f"Erro de rede ao buscar klines para {symbol}: {e}")
        return None

def get_ticker_data():
    """Busca os dados de ticker de 24h para todas as moedas, com cache."""
    cache_args = {'func': 'get_ticker_data'}
    cached_data = robust_services.data_cache.get(cache_args, ttl=60)
    if cached_data is not None: return cached_data
        
    robust_services.rate_limiter.wait_if_needed()
    try:
        response = requests.get("https://api.binance.com/api/v3/ticker/24hr", timeout=10)
        response.raise_for_status()
        ticker_data = {item['symbol']: item for item in response.json()}
        robust_services.data_cache.set(cache_args, ticker_data)
        return ticker_data
    except requests.exceptions.RequestException as e:
        logging.error(f"Erro ao buscar dados de 24h (ticker): {e}")
        return {}

def get_market_caps_coingecko(symbols_to_monitor, coingecko_mapping):
    """Busca o valor de mercado (market cap) para uma lista de moedas via CoinGecko."""
    market_caps = {}
    coin_ids_to_fetch = []
    symbol_to_coin_id = {}

    all_coins = cg_client.get_coins_list()

    for binance_symbol in symbols_to_monitor:
        base_asset = binance_symbol.replace('USDT', '').upper()
        coingecko_name = coingecko_mapping.get(base_asset)
        if coingecko_name:
            coin_id = next((item['id'] for item in all_coins if item['name'].lower() == coingecko_name.lower()), None)
            if coin_id:
                coin_ids_to_fetch.append(coin_id)
                symbol_to_coin_id[coin_id] = binance_symbol

    if not coin_ids_to_fetch: return {}

    cache_key = {'func': 'get_market_caps_coingecko', 'ids': tuple(sorted(coin_ids_to_fetch))}
    cached_data = robust_services.data_cache.get(cache_key, ttl=300)
    if cached_data is not None: return cached_data

    try:
        robust_services.rate_limiter.wait_if_needed()
        response = cg_client.get_coins_markets(vs_currency='usd', ids=','.join(coin_ids_to_fetch))
        for coin_data in response:
            original_binance_symbol = symbol_to_coin_id.get(coin_data['id'])
            if original_binance_symbol:
                market_caps[original_binance_symbol] = coin_data.get('market_cap')
        robust_services.data_cache.set(cache_key, market_caps)
        return market_caps
    except Exception as e:
        logging.error(f"Erro ao buscar market caps da CoinGecko: {e}")
        return {}

def get_coingecko_global_mapping():
    """
    Busca a lista de moedas da CoinGecko para mapear S√≠mbolo -> Nome.
    Utiliza um cache local que √© atualizado a cada 24 horas.
    """
    cached_mapping = load_coin_mapping_cache()
    if cached_mapping is not None:
        return cached_mapping

    logging.info("Buscando novo mapeamento de nomes da CoinGecko (cache expirado ou inexistente)...")
    robust_services.rate_limiter.wait_if_needed()
    try:
        coins_list = cg_client.get_coins_list()
        mapping = {coin['symbol'].upper(): coin['name'] for coin in coins_list}

        save_coin_mapping_cache(mapping) # Salva o novo mapeamento no cache

        logging.info("Mapeamento de nomes CoinGecko carregado e cache atualizado.")
        return mapping
    except Exception as e:
        logging.error(f"N√£o foi poss√≠vel buscar mapeamento da CoinGecko: {e}")
        return {}

def fetch_all_binance_symbols_startup(existing_config):
    """Busca todos os s√≠mbolos USDT da Binance na inicializa√ß√£o."""
    logging.info("Buscando lista de moedas da Binance...")
    robust_services.rate_limiter.wait_if_needed()
    try:
        response = requests.get("https://api.binance.com/api/v3/exchangeInfo", timeout=15)
        response.raise_for_status()
        symbols = sorted([s['symbol'] for s in response.json()['symbols'] if s['symbol'].endswith('USDT')])
        logging.info(f"{len(symbols)} moedas encontradas na Binance.")
        return symbols
    except Exception as e:
        logging.error(f"N√£o foi poss√≠vel buscar a lista de moedas da Binance: {e}")
        logging.warning("Retornando moedas da configura√ß√£o existente como fallback.")
        return [c['symbol'] for c in existing_config.get('cryptos_to_monitor', [])]

def _get_sound_for_trigger(trigger_key, sound_config):
    """Determina o som apropriado para um gatilho de alerta com base na sua chave program√°tica."""
    if not sound_config:
        return os.path.join('sons', 'Alerta.mp3')

    key_to_config_map = {
        'RSI_SOBRECOMPRA': 'overbought',
        'RSI_SOBREVENDA': 'oversold',
        'CRUZ_DOURADA': 'golden_cross',
        'CRUZ_DA_MORTE': 'death_cross',
        'PRECO_ACIMA': 'price_above',
        'PRECO_ABAIXO': 'price_below',
        'VOLUME_ANORMAL': 'high_volume',
        'FUGA_CAPITAL': 'critical_alert',
        'ENTRADA_CAPITAL': 'critical_alert',
        'HILO_COMPRA': 'golden_cross',
        'HILO_VENDA': 'death_cross',
    }

    default_sounds = {
        'overbought': 'sobrecomprado.wav',
        'oversold': 'sobrevendido.wav',
        'golden_cross': 'cruzamentoAlta.wav',
        'death_cross': 'cruzamentoBaixa.wav',
        'price_above': 'precoAcima.wav',
        'price_below': 'precoAbaixo.wav',
        'high_volume': 'volumeAlto.wav',
        'critical_alert': 'alertaCritico.wav',
        'default_alert': 'Alerta.mp3',
    }

    config_key = key_to_config_map.get(trigger_key, 'default_alert')
    sound_file = sound_config.get(config_key, default_sounds.get(config_key))

    return os.path.join('sons', sound_file)

def _check_and_trigger_alerts(symbol, alert_config, analysis_data, data_queue, sound_config):
    """Verifica e dispara alertas para um s√≠mbolo com base nas condi√ß√µes configuradas."""
    conditions = alert_config.get('conditions', {})

    triggered_conditions = alert_config.get('triggered_conditions', {})
    if isinstance(triggered_conditions, list):
        triggered_conditions = {}

    alert_cooldown_minutes = alert_config.get('alert_cooldown_minutes', 60)

    current_price = analysis_data['current_price']
    rsi = analysis_data['rsi_value']
    volume_24h = analysis_data['volume_24h']
    price_change_24h = analysis_data['price_change_24h']
    market_cap = analysis_data.get('market_cap')

    # Dicion√°rio para mapear condi√ß√£o a chave e mensagem
    alert_definitions = {
        'preco_baixo': {'key': 'PRECO_ABAIXO', 'msg': f"Pre√ßo Abaixo de ${conditions.get('preco_baixo', {}).get('value', 0):.2f}"},
        'preco_alto': {'key': 'PRECO_ACIMA', 'msg': f"Pre√ßo Acima de ${conditions.get('preco_alto', {}).get('value', 0):.2f}"},
        'rsi_sobrevendido': {'key': 'RSI_SOBREVENDA', 'msg': f"RSI Sobrevendido (<= {conditions.get('rsi_sobrevendido', {}).get('value', 30):.1f})"},
        'rsi_sobrecomprado': {'key': 'RSI_SOBRECOMPRA', 'msg': f"RSI Sobrecomprado (>= {conditions.get('rsi_sobrecomprado', {}).get('value', 70):.1f})"},
        'bollinger_abaixo': {'key': 'PRECO_ABAIXO_BANDA_INFERIOR', 'msg': "Pre√ßo Abaixo da Banda Inferior de Bollinger"},
        'bollinger_acima': {'key': 'PRECO_ACIMA_BANDA_SUPERIOR', 'msg': "Pre√ßo Acima da Banda Superior de Bollinger"},
        'macd_cruz_baixa': {'key': 'CRUZAMENTO_MACD_BAIXA', 'msg': "MACD: Cruzamento de Baixa"},
        'macd_cruz_alta': {'key': 'CRUZAMENTO_MACD_ALTA', 'msg': "MACD: Cruzamento de Alta"},
        'mme_cruz_morte': {'key': 'CRUZ_DA_MORTE', 'msg': "MME: Cruz da Morte (50/200)"},
        'mme_cruz_dourada': {'key': 'CRUZ_DOURADA', 'msg': "MME: Cruz Dourada (50/200)"},
        'fuga_capital': {'key': 'FUGA_CAPITAL', 'msg': "Detectada poss√≠vel fuga de capital significativa"},
        'entrada_capital': {'key': 'ENTRADA_CAPITAL', 'msg': "Detectada poss√≠vel entrada de capital significativa"},
        'hilo_compra': {'key': 'HILO_COMPRA', 'msg': "HiLo: Sinal de Compra"},
        'hilo_venda': {'key': 'HILO_VENDA', 'msg': "HiLo: Sinal de Venda"},
    }

    active_triggers = []

    # L√≥gica de verifica√ß√£o de condi√ß√µes
    if conditions.get('preco_baixo', {}).get('enabled') and current_price <= conditions['preco_baixo']['value']: active_triggers.append(alert_definitions['preco_baixo'])
    if conditions.get('preco_alto', {}).get('enabled') and current_price >= conditions['preco_alto']['value']: active_triggers.append(alert_definitions['preco_alto'])
    if conditions.get('rsi_sobrevendido', {}).get('enabled') and rsi <= conditions['rsi_sobrevendido']['value']: active_triggers.append(alert_definitions['rsi_sobrevendido'])
    if conditions.get('rsi_sobrecomprado', {}).get('enabled') and rsi >= conditions['rsi_sobrecomprado']['value']: active_triggers.append(alert_definitions['rsi_sobrecomprado'])
    if conditions.get('bollinger_abaixo', {}).get('enabled') and analysis_data.get('bollinger_signal') == "Abaixo da Banda": active_triggers.append(alert_definitions['bollinger_abaixo'])
    if conditions.get('bollinger_acima', {}).get('enabled') and analysis_data.get('bollinger_signal') == "Acima da Banda": active_triggers.append(alert_definitions['bollinger_acima'])
    if conditions.get('macd_cruz_baixa', {}).get('enabled') and analysis_data.get('macd_signal') == "Cruzamento de Baixa": active_triggers.append(alert_definitions['macd_cruz_baixa'])
    if conditions.get('macd_cruz_alta', {}).get('enabled') and analysis_data.get('macd_signal') == "Cruzamento de Alta": active_triggers.append(alert_definitions['macd_cruz_alta'])
    if conditions.get('mme_cruz_morte', {}).get('enabled') and analysis_data.get('mme_cross') == "Cruz da Morte": active_triggers.append(alert_definitions['mme_cruz_morte'])
    if conditions.get('mme_cruz_dourada', {}).get('enabled') and analysis_data.get('mme_cross') == "Cruz Dourada": active_triggers.append(alert_definitions['mme_cruz_dourada'])
    if conditions.get('hilo_compra', {}).get('enabled') and analysis_data.get('hilo_signal') == "HiLo Buy": active_triggers.append(alert_definitions['hilo_compra'])
    if conditions.get('hilo_venda', {}).get('enabled') and analysis_data.get('hilo_signal') == "HiLo Sell": active_triggers.append(alert_definitions['hilo_venda'])

    fuga_capital_config = conditions.get('fuga_capital_significativa', {})
    if fuga_capital_config.get('enabled') and market_cap is not None and market_cap > 0:
        try:
            percent_mcap_str, percent_price_str = fuga_capital_config['value'].split(',')
            if (volume_24h / market_cap * 100) > float(percent_mcap_str) and price_change_24h < float(percent_price_str):
                active_triggers.append(alert_definitions['fuga_capital'])
        except (ValueError, TypeError):
            logging.warning(f"Configura√ß√£o de alerta 'fuga de capital' inv√°lida para {symbol}.")

    entrada_capital_config = conditions.get('entrada_capital_significativa', {})
    if entrada_capital_config.get('enabled') and market_cap is not None and market_cap > 0:
        try:
            percent_mcap_str, percent_price_str = entrada_capital_config['value'].split(',')
            if (volume_24h / market_cap * 100) > float(percent_mcap_str) and price_change_24h > float(percent_price_str):
                active_triggers.append(alert_definitions['entrada_capital'])
        except (ValueError, TypeError):
            logging.warning(f"Configura√ß√£o de alerta 'entrada de capital' inv√°lida para {symbol}.")

    now = datetime.now()
    for trigger in active_triggers:
        trigger_key = trigger['key']

        last_triggered_str = triggered_conditions.get(trigger_key)
        if last_triggered_str:
            try:
                last_triggered_time = datetime.fromisoformat(last_triggered_str)
                if now - last_triggered_time < timedelta(minutes=alert_cooldown_minutes):
                    continue
            except ValueError:
                logging.warning(f"Formato de data inv√°lido para a √∫ltima ativa√ß√£o do alerta '{trigger_key}' para {symbol}. Ignorando cooldown para este ciclo.")

        market_cap_str = f"${market_cap:,.0f}" if market_cap is not None else "N/A"
        user_notes = alert_config.get('notes', '').strip()
        summary = ALERT_SUMMARIES.get(trigger_key, "Consulte o guia para mais detalhes.")

        observacoes = summary
        if user_notes:
            observacoes = f"{user_notes}\n\nAn√°lise: {summary}"

        formatted_message = (
            f"üö® ALERTA: {symbol} üö®\n\n"
            f"Disparo: {trigger['msg']} (Atual: ${current_price:,.2f})\n"
            f"Pre√ßo Atual: ${current_price:,.2f}\n"
            f"Volume 24h: ${volume_24h:,.0f}\n"
            f"Capitaliza√ß√£o de Mercado: {market_cap_str}\n"
            f"Varia√ß√£o 24h: {price_change_24h:.2f}%\n\n"
            f"Observa√ß√µes: {observacoes}"
        )

        sound_path = _get_sound_for_trigger(trigger_key, sound_config)
        alert_payload = {
            'symbol': symbol,
            'message': formatted_message,
            'sound': sound_path,
            'trigger': trigger_key,
            'analysis_data': analysis_data
        }
        data_queue.put({'type': 'alert', 'payload': alert_payload})
        triggered_conditions[trigger_key] = now.isoformat()

    active_trigger_keys = {t['key'] for t in active_triggers}
    alert_config['triggered_conditions'] = {k: v for k, v in triggered_conditions.items() if k in active_trigger_keys}

def _analyze_symbol(symbol, ticker_data, market_cap=None):
    """Coleta e analisa todos os dados t√©cnicos para um √∫nico s√≠mbolo."""
    analysis_result = {'symbol': symbol, 'current_price': 0.0, 'price_change_24h': 0.0, 'volume_24h': 0.0,
                       'rsi_value': 0.0, 'rsi_signal': "N/A", 'bollinger_signal': "Nenhum",
                       'macd_signal': "Nenhum", 'mme_cross': "Nenhum", 'hilo_signal': "Nenhum", 'market_cap': market_cap}

    symbol_ticker = ticker_data.get(symbol, {})
    analysis_result['current_price'] = robust_services.DataValidator.safe_price(symbol_ticker.get('lastPrice'))
    analysis_result['price_change_24h'] = robust_services.DataValidator.safe_float(symbol_ticker.get('priceChangePercent'))
    analysis_result['volume_24h'] = robust_services.DataValidator.safe_float(symbol_ticker.get('quoteVolume'))

    df = get_klines_data(symbol)
    if df is None or df.empty: return analysis_result

    rsi_value, _, _ = calculate_rsi(df)
    upper_band, lower_band, _, _ = calculate_bollinger_bands(df)
    macd_cross = calculate_macd(df)
    _, _, hilo_signal = calculate_hilo_signals(df)
    emas = calculate_emas(df, periods=[50, 200])

    analysis_result['hilo_signal'] = hilo_signal
    analysis_result['rsi_value'] = rsi_value if rsi_value else 0.0
    analysis_result['rsi_signal'] = f"{rsi_value:.2f}" if rsi_value else "N/A"
    
    if upper_band > 0 and analysis_result['current_price'] > 0:
        if analysis_result['current_price'] > upper_band: analysis_result['bollinger_signal'] = "Acima da Banda"
        elif analysis_result['current_price'] < lower_band: analysis_result['bollinger_signal'] = "Abaixo da Banda"
            
    analysis_result['macd_signal'] = macd_cross
    
    if 50 in emas and 200 in emas and len(emas[50]) > 1 and len(emas[200]) > 1:
        if emas[50].iloc[-2] < emas[200].iloc[-2] and emas[50].iloc[-1] > emas[200].iloc[-1]: analysis_result['mme_cross'] = "Cruz Dourada"
        elif emas[50].iloc[-2] > emas[200].iloc[-2] and emas[50].iloc[-1] < emas[200].iloc[-1]: analysis_result['mme_cross'] = "Cruz da Morte"
    
    return analysis_result

def run_monitoring_cycle(config, data_queue, stop_event, coingecko_mapping):
    """Ciclo principal de monitoramento que roda em segundo plano para buscar e analisar dados."""
    logging.info("Ciclo de monitoramento iniciado.")
    
    while not stop_event.is_set():
        check_interval = config.get("check_interval_seconds", 300)
        data_queue.put({'type': 'start_countdown', 'payload': {'seconds': check_interval}})
        monitored_cryptos = copy.deepcopy(config.get("cryptos_to_monitor", []))
        sound_config = config.get('sound_config', {})
        if not monitored_cryptos:
            time.sleep(5)
            continue

        ticker_data = get_ticker_data()
        market_caps_data = get_market_caps_coingecko([c['symbol'] for c in monitored_cryptos], coingecko_mapping)

        if not ticker_data:
            logging.warning("N√£o foi poss√≠vel obter os dados do ticker. Pulando este ciclo.")
            time.sleep(config.get("check_interval_seconds", 300))
            continue

        for crypto_config in monitored_cryptos:
            if stop_event.is_set(): break
            symbol = crypto_config.get('symbol')
            if not symbol or not robust_services.DataValidator.validate_symbol(symbol): continue

            analysis_data = _analyze_symbol(symbol, ticker_data, market_caps_data.get(symbol))
            data_queue.put({'type': 'data', 'payload': analysis_data})

            if alert_config := crypto_config.get('alert_config'):
                _check_and_trigger_alerts(symbol, alert_config, analysis_data, data_queue, sound_config)

            time.sleep(0.2)

        if not stop_event.is_set():
            logging.info(f"Ciclo de monitoramento completo. Aguardando {config.get('check_interval_seconds', 300)}s.")
            time.sleep(config.get("check_interval_seconds", 300))
    logging.info("Ciclo de monitoramento terminado.")

def run_single_symbol_update(symbol, config, data_queue, coingecko_mapping):
    """Executa uma atualiza√ß√£o de dados para uma √∫nica moeda, usado para refresh manual."""
    logging.info(f"Iniciando atualiza√ß√£o for√ßada para {symbol}...")
    crypto_config = next((c for c in config.get("cryptos_to_monitor", []) if c['symbol'] == symbol), None)
    if not crypto_config: return

    ticker_data = get_ticker_data()
    market_caps_data = get_market_caps_coingecko([symbol], coingecko_mapping)
    analysis_data = _analyze_symbol(symbol, ticker_data, market_caps_data.get(symbol))
    data_queue.put({'type': 'data', 'payload': analysis_data})
    logging.info(f"Atualiza√ß√£o para {symbol} enviada para a interface.")

def fetch_initial_data(config, data_queue):
    """Busca todos os dados iniciais necess√°rios para a aplica√ß√£o em uma thread separada."""
    try:
        last_fetch_time = get_last_fetch_timestamp()
        current_time = time.time()

        # Se a √∫ltima busca foi a menos de 5 minutos (300s), pula a busca
        if current_time - last_fetch_time < 300:
            data_queue.put({'status': 'skipped', 'data': "Busca de dados recentes. Usando cache."})
            # Mesmo pulando, precisamos dos dados para iniciar a app. Assumimos que est√£o em cache.
            # Esta parte pode precisar de mais robustez se o cache puder estar vazio.
            all_symbols = fetch_all_binance_symbols_startup(config) # Pode vir do cache da exchangeInfo
            mapping = get_coingecko_global_mapping() # Pode vir do cache da lista de moedas
            data_queue.put({'status': 'done', 'data': {'symbols': all_symbols, 'mapping': mapping}})
            return

        data_queue.put({'status': 'symbols', 'data': None})
        all_symbols = fetch_all_binance_symbols_startup(config)

        data_queue.put({'status': 'mapping', 'data': None})
        mapping = get_coingecko_global_mapping()

        update_last_fetch_timestamp() # Atualiza o timestamp ap√≥s uma busca bem sucedida

        data_queue.put({'status': 'done', 'data': {'symbols': all_symbols, 'mapping': mapping}})
    except Exception as e:
        logging.critical(f"Erro cr√≠tico ao buscar dados iniciais: {e}")
        data_queue.put({'status': 'error', 'data': str(e)})

def get_btc_dominance():
    """Busca a domin√¢ncia de mercado do BTC a partir da CoinGecko."""
    try:
        cache_key = {'func': 'get_btc_dominance'}
        if cached_data := robust_services.data_cache.get(cache_key, ttl=300):
            return cached_data

        robust_services.rate_limiter.wait_if_needed()
        # A API da CoinGecko retorna um dicion√°rio diretamente.
        # A chave 'data' cont√©m as informa√ß√µes globais.
        global_data = cg_client.get_global()
        
        # O valor da domin√¢ncia do BTC est√° em 'data' -> 'market_cap_percentage' -> 'btc'
        btc_dominance = global_data.get('market_cap_percentage', {}).get('btc')

        if btc_dominance is not None and isinstance(btc_dominance, (int, float)):
            result = f"{btc_dominance:.2f}%"
            robust_services.data_cache.set(cache_key, result)
            return result
        else:
            logging.warning(f"Domin√¢ncia BTC n√£o encontrada ou em formato inv√°lido na resposta da API: {global_data}")
            return "N/A"
            
    except Exception as e:
        logging.error(f"N√£o foi poss√≠vel buscar a domin√¢ncia do BTC: {e}")
        return "Erro"
